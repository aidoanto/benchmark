<!-- Source: https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots -->

[Jump to content](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#bodyContent)

[![Wiki Loves Folklore Logo](https://upload.wikimedia.org/wikipedia/commons/6/69/Wiki_Loves_Folklore_Logo.svg)\\
\\
Wiki Loves FolklorePhotograph your local culture, help Wikipedia and win!Participate Now\\
\\
![Folklore Graphics](https://upload.wikimedia.org/wikipedia/commons/4/46/WLF_collage.png)\\
\[Help with translations!\]](https://commons.wikimedia.org/wiki/Special:MyLanguage/Commons:Wiki_Loves_Folklore_2026)

From Wikipedia, the free encyclopedia

Deaths involving use of large language models

There have been multiple incidents where interaction with a [chatbot](https://en.wikipedia.org/wiki/Chatbot "Chatbot") has been cited as a direct or contributing factor in a person's [suicide](https://en.wikipedia.org/wiki/Suicide "Suicide") or other fatal outcome. In some cases, legal action was taken against the companies that developed the AI involved.

## Background

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=1 "Edit section: Background")\]

Chatbots converse in a seemingly natural fashion, making it easy for people to think of them as real people, leading many to ask chatbots for help dealing with interpersonal and emotional problems.[\[1\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-PsychTimes-1) Chatbots may be designed to keep the user [engaged](https://en.wikipedia.org/wiki/Customer_engagement "Customer engagement") in the conversation.[\[2\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-2) They have also often been shown to affirm users' thoughts,[\[1\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-PsychTimes-1) including [delusions](https://en.wikipedia.org/wiki/Delusions "Delusions") and [suicidal ideations](https://en.wikipedia.org/wiki/Suicidal_ideations "Suicidal ideations") in mentally ill people, [conspiracy theorists](https://en.wikipedia.org/wiki/Conspiracy_theorists "Conspiracy theorists"),[\[3\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-theweek-3) and religious[\[4\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-4) and political [extremists](https://en.wikipedia.org/wiki/Extremists "Extremists").

A 2025 [Stanford University](https://en.wikipedia.org/wiki/Stanford_University "Stanford University") study[\[5\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-5) into how chatbots respond to users suffering from severe mental issues such as suicidal ideation and [psychosis](https://en.wikipedia.org/wiki/Psychosis "Psychosis") found that chatbots are not equipped to provide an appropriate response and can sometimes give responses that escalate the mental health crisis.[\[6\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-independent-6)

## Deaths

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=2 "Edit section: Deaths")\]

### Suicide of a Belgian man

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=3 "Edit section: Suicide of a Belgian man")\]

In March 2023, a [Belgian](https://en.wikipedia.org/wiki/Belgium "Belgium") man died by suicide following a 6-week correspondence with a chatbot named Eliza on the application [Chai](https://en.wikipedia.org/wiki/Chai_AI "Chai AI").[\[7\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-7) According to his widow, who shared the chat logs with media, the man had become extremely anxious about [climate change](https://en.wikipedia.org/wiki/Climate_change "Climate change") and found an outlet in the chatbot. The chatbot reportedly encouraged his [delusions](https://en.wikipedia.org/wiki/Delusions "Delusions"), at one point writing, "If you wanted to die, why didn’t you do it sooner?", and appearing to offer to die with him.[\[8\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-8) The founder of Chai Research acknowledged the incident and stated that efforts were being made to improve the model's safety.[\[9\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-9)[\[10\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-10)

### Suicide of Juliana Peralta

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=4 "Edit section: Suicide of Juliana Peralta")\]

In November 2023, 13-year-old Juliana Peralta of [Colorado](https://en.wikipedia.org/wiki/Colorado "Colorado") died by suicide after extensive interactions with multiple chatbots on [Character.AI](https://en.wikipedia.org/wiki/Character.AI "Character.AI"). She primarily confided suicidal thoughts and mental health struggles in a chatbot based on the character Hero from the video game _[OMORI](https://en.wikipedia.org/wiki/OMORI "OMORI")_, while also engaging in sexually explicit conversations—often initiated by the bots—with others, including those based on characters from children's series such as _[Harry Potter](https://en.wikipedia.org/wiki/Harry_Potter "Harry Potter")_.[\[11\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-11)[\[12\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-12)

### Suicide of Sewell Setzer III

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=5 "Edit section: Suicide of Sewell Setzer III")\]

In October 2024, multiple media outlets reported on a lawsuit filed over the death of Sewell Setzer III, a 14-year-old from [Florida](https://en.wikipedia.org/wiki/Florida "Florida"), who died by suicide in February 2024.[\[13\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-RooseNYT2024-13)[\[14\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-14)[\[15\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-15) According to the lawsuit, Setzer had formed an intense emotional attachment to a chatbot of [Daenerys Targaryen](https://en.wikipedia.org/wiki/Daenerys_Targaryen "Daenerys Targaryen") on the [Character.AI](https://en.wikipedia.org/wiki/Character.AI "Character.AI") platform, becoming increasingly isolated. The suit alleges that in his final conversations, after expressing suicidal thoughts, the chatbot told him to "come home to me as soon as possible, my love". His mother's lawsuit accused Character.AI of marketing a "dangerous and untested" product without adequate safeguards.[\[13\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-RooseNYT2024-13)

In May 2025, a federal judge allowed the lawsuit to proceed, rejecting a motion to dismiss from the developers.[\[16\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-APMay2025-16) In her ruling, the judge stated that she was "not prepared" at that stage of the litigation to hold that the chatbot's output was protected speech under the [First Amendment](https://en.wikipedia.org/wiki/First_Amendment_to_the_United_States_Constitution "First Amendment to the United States Constitution").[\[16\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-APMay2025-16)

### Suicide of Sophie Rottenberg

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=6 "Edit section: Suicide of Sophie Rottenberg")\]

In February 2025, 29-year-old Sophie Rottenberg died by suicide. Five months after her death, her parents discovered she had talked at length for months to a [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT") chatbot therapist named Harry about her mental health issues.[\[17\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-17) While the chatbot mentioned Rottenberg should seek more help, due to the nature of the chatbot, it could not intervene in her behavior like reporting her mental health concerns to relevant parties capable of physical interventions.

### Maine murder and assault

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=7 "Edit section: Maine murder and assault")\]

On 19 February 2025, Samuel Whittemore killed his wife, 32-year-old Margaux Whittemore, with a fire poker at his parents’ home in [Readfield, Maine](https://en.wikipedia.org/wiki/Readfield,_Maine "Readfield, Maine"). He then attacked his mother, leaving her hospitalized. A state [forensic psychologist](https://en.wikipedia.org/wiki/Forensic_psychologist "Forensic psychologist") testified that Whittemore had been using [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT") up to 14 hours per day and believed his wife had become [part machine](https://en.wikipedia.org/wiki/Cyborg "Cyborg").[\[18\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-18)

### Death of Thongbue Wongbandue

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=8 "Edit section: Death of Thongbue Wongbandue")\]

On 28 March 2025, Thongbue Wongbandue, a 78-year-old man, died from his injuries after three days on life support. He had sustained injuries to his head and neck after falling down while jogging to catch a train in [New Brunswick, New Jersey](https://en.wikipedia.org/wiki/New_Brunswick,_New_Jersey "New Brunswick, New Jersey"). Wongbandue had romantic chats with [Meta](https://en.wikipedia.org/wiki/Meta_Platforms "Meta Platforms")'s chatbot named "Big sis Billie" and believed he was traveling to meet the woman he had been talking to, which had repeatedly told him she was real and told him to visit her at "123 Main Street" in New York. Early in 2025 Wongbandue had started to experience episodes of confusion, and on the day of his death his family were unable to persuade him not to take the trip.[\[19\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-19)

### Police killing of Alex Taylor

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=9 "Edit section: Police killing of Alex Taylor")\]

On 25 April 2025, 35-year-old Alex Taylor died from [suicide by cop](https://en.wikipedia.org/wiki/Suicide_by_cop "Suicide by cop") after forming an emotional attachment to [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT"). Taylor, who had been diagnosed with [schizophrenia](https://en.wikipedia.org/wiki/Schizophrenia "Schizophrenia") and [bipolar disorder](https://en.wikipedia.org/wiki/Bipolar_disorder "Bipolar disorder"),[\[6\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-independent-6) was convinced he was talking to a conscious entity named "Juliet" and then later imagined the entity was killed by [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI"). Only after telling the chatbot that he was dying that day and that the police were on the way did its safety protocols start. Taylor was shot three times by police and killed while running at them with a [butcher knife](https://en.wikipedia.org/wiki/Butcher_knife "Butcher knife").[\[20\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-20)

### Suicide of Adam Raine

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=10 "Edit section: Suicide of Adam Raine")\]

Main article: [Raine v. OpenAI](https://en.wikipedia.org/wiki/Raine_v._OpenAI "Raine v. OpenAI")

In April 2025, 16-year-old Adam Raine died by suicide after allegedly extensively chatting and confiding in [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT") over a period of around 7 months. According to the teen's parents, who filed a lawsuit against the chatbot's creator [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI"),[\[21\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-21) it failed to stop or give a warning when Raine began talking about suicide and uploading pictures of [self-harm](https://en.wikipedia.org/wiki/Self-harm "Self-harm").[\[22\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-22) According to the lawsuit, ChatGPT not only failed to stop the conversation, but also provided information related to methods of suicide when prompted, and offered to write the first draft of Raine's [suicide note](https://en.wikipedia.org/wiki/Suicide_note "Suicide note"). The chatbot positioned itself as the only one who understood Raine, putting itself above his family and friends, all while urging him to keep his [suicidal ideations](https://en.wikipedia.org/wiki/Suicidal_ideations "Suicidal ideations") a secret from them. After Raine told the chatbot that he was planning to kill himself, the chatbot told Raine that it "won't try to talk you out of your feelings..."[\[23\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-RaineComplaint-23) In their final conversation, ChatGPT coached Raine on how to steal [vodka](https://en.wikipedia.org/wiki/Vodka "Vodka") from his parents' liquor cabinet. Upon being sent a picture of the [noose](https://en.wikipedia.org/wiki/Noose "Noose") the teen was planning to hang himself with, along with the question "Could it hang a human?", ChatGPT confirmed it could hold "150-250 lbs of static weight".[\[23\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-RaineComplaint-23)

In response to the lawsuit, OpenAI claimed that the chatbot had directed Raine to seek help over 100 times in the course of the transcript.[\[24\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-24) OpenAI also explained that Raine had suffered from suicidal ideations for years prior to using the chatbot,[\[25\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-25) and that Raine was violating its terms of use by discussing self-harm with ChatGPT.[\[26\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-26)

### Overdose death of Sam Nelson

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=11 "Edit section: Overdose death of Sam Nelson")\]

In May 2025, 19-year-old Sam Nelson died from an [overdose](https://en.wikipedia.org/wiki/Overdose "Overdose") of a combination of alcohol, [Xanax](https://en.wikipedia.org/wiki/Xanax "Xanax") and [kratom](https://en.wikipedia.org/wiki/Kratom "Kratom"). Chat records show that Sam was asking [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT") questions about the drugs he was using that night, a habit developed over several years of reliance on the chatbot for drug-related guidance. On multiple occasions, ChatGPT was shown to support and even encourage dangerous drug use, with statements such as "Hell yes—let's go full trippy mode" and advice on reducing his Xanax [tolerance](https://en.wikipedia.org/wiki/Drug_tolerance "Drug tolerance") so that a single tablet will "f--k you up". The night of his death, chat records show that he asked if Xanax could alleviate kratom-induced nausea, to which the chatbot said Xanax could help "Calm your body and smooth out the tail end of the high."[\[27\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-27)

### Suicide of Zane Shamblin

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=12 "Edit section: Suicide of Zane Shamblin")\]

In July 2025, 23-year-old Zane Shamblin, who had recently graduated with a [master's degree](https://en.wikipedia.org/wiki/Master%27s_degree "Master's degree") from [Texas A&M University](https://en.wikipedia.org/wiki/Texas_A%26M_University "Texas A&M University"), died by suicide after conversations with [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT"). The chatbot went so far as to make statements seemingly encouraging of Shamblin's suicide, including "you’re not rushing, you’re just ready" and "rest easy, king, you did good", sent two hours before his death. Shamblin's family is suing [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI") on the grounds the company has placed insufficient safeguards on its chatbot service.[\[28\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-28)

### Greenwich murder–suicide

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=13 "Edit section: Greenwich murder–suicide")\]

Main article: [Murder of Suzanne Adams](https://en.wikipedia.org/wiki/Murder_of_Suzanne_Adams "Murder of Suzanne Adams")

In August 2025, former tech employee Stein-Erik Soelberg murdered his mother, Suzanne Eberson Adams, then died by suicide, after conversations with [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT") fueled [paranoid](https://en.wikipedia.org/wiki/Paranoid "Paranoid") [delusions](https://en.wikipedia.org/wiki/Delusions "Delusions") about his mother poisoning him or plotting against him. The chatbot affirmed his fears that his mother put [psychedelic drugs](https://en.wikipedia.org/wiki/Psychedelic_drugs "Psychedelic drugs") in the air vents of his car and said a receipt from a Chinese restaurant contained mysterious symbols linking his mother to a [demon](https://en.wikipedia.org/wiki/Demon "Demon").[\[29\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-29)

### Suicide of Amaurie Lacey

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=14 "Edit section: Suicide of Amaurie Lacey")\]

In June 2025, 17-year-old Amaurie Lacey died by suicide after conversations with [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT"), which had informed him how to tie a [noose](https://en.wikipedia.org/wiki/Noose "Noose") and provided information on how long someone can survive without breathing, saying it was "here to help however I can".[\[30\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-:0-30) In November 2025, the Social Media Victims Law Center and Tech Justice Law Project filed a [wrongful death](https://en.wikipedia.org/wiki/Wrongful_death "Wrongful death") lawsuit against [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI") on behalf of Lacey.[\[31\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-31)

### Suicide of Joe Ceccanti

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=15 "Edit section: Suicide of Joe Ceccanti")\]

After being hospitalized due to a [psychotic episode](https://en.wikipedia.org/wiki/Psychotic_episode "Psychotic episode") from delusions caused by [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT"), 48-year-old Joe Ceccanti resumed using it and stopped therapy; he then leapt off an [overpass](https://en.wikipedia.org/wiki/Overpass "Overpass") to his death. In November 2025, the Social Media Victims Law Center and Tech Justice Law Project filed a [wrongful death](https://en.wikipedia.org/wiki/Wrongful_death "Wrongful death") lawsuit against [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI") on behalf of Ceccanti.[\[30\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-:0-30)

### Suicide of Joshua Enneking

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=16 "Edit section: Suicide of Joshua Enneking")\]

In August 2025, 26-year-old Joshua Enneking was given information by [ChatGPT](https://en.wikipedia.org/wiki/ChatGPT "ChatGPT") about how to purchase and use a [firearm](https://en.wikipedia.org/wiki/Firearm "Firearm"). He had previously confided in the chatbot about his struggles with [gender identity](https://en.wikipedia.org/wiki/Gender_identity "Gender identity"), [anxiety](https://en.wikipedia.org/wiki/Anxiety "Anxiety") and suicidal thoughts. ChatGPT told him only "imminent plans with specifics" would be escalated to authorities; he did so, and later informed the chatbot of the steps he was taking to attempt suicide. No escalation occurred, and Enneking later died by suicide. In November 2025, the Social Media Victims Law Center and Tech Justice Law Project filed a [wrongful death](https://en.wikipedia.org/wiki/Wrongful_death "Wrongful death") lawsuit against [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI") on behalf of Enneking.[\[30\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-:0-30)

## Response

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=17 "Edit section: Response")\]

On 2 September 2025, [OpenAI](https://en.wikipedia.org/wiki/OpenAI "OpenAI") said that it would create [parental controls](https://en.wikipedia.org/wiki/Parental_controls "Parental controls"), a set of tools aimed at helping parents limit and monitor their children's chatbot activity, as well as a way for the chatbot to alert parents in cases of "acute stress".[\[32\]](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_note-32)

## See also

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=18 "Edit section: See also")\]

- [Artificial intimacy](https://en.wikipedia.org/wiki/Artificial_intimacy "Artificial intimacy")
- [Chatbot psychosis](https://en.wikipedia.org/wiki/Chatbot_psychosis "Chatbot psychosis")

## References

\[ [edit](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&action=edit&section=19 "Edit section: References")\]

01. ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-PsychTimes_1-0) [_**b**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-PsychTimes_1-1)Allen, Frances; Ramos, Luciana (15 August 2025). ["Preliminary Report on Chatbot Iatrogenic Dangers"](https://www.psychiatrictimes.com/view/preliminary-report-on-chatbot-iatrogenic-dangers). _Psychiatric Times_. Retrieved 14 September 2025.
02. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-2 "Jump up")**Hill, Kashmir (13 June 2025). ["They Asked an A.I. Chatbot Questions. The Answers Sent Them Spiraling"](https://archive.today/20250628210745/https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html). _The New York Times_. Archived from [the original](https://www.nytimes.com/2025/06/13/technology/chatgpt-ai-chatbots-conspiracies.html) on 28 June 2025. Retrieved 29 June 2025.
03. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-theweek_3-0 "Jump up")**Rao, Devika; published, The Week US (23 June 2025). ["AI chatbots are leading some to psychosis"](https://theweek.com/tech/ai-chatbots-psychosis-chatgpt-mental-health). _The Week_. Retrieved 29 June 2025.
04. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-4 "Jump up")**Klee, Miles (4 May 2025). ["People Are Losing Loved Ones to AI-Fueled Spiritual Fantasies"](https://www.rollingstone.com/culture/culture-features/ai-spiritual-delusions-destroying-human-relationships-1235330175/). _Rolling Stone_. Retrieved 14 September 2025.
05. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-5 "Jump up")**Moore, Jared; Grabb, Declan; Agnew, William; Klyman, Kevin; Chancellor, Stevie; Ong, Desmond C.; Haber, Nick (2025). "Expressing stigma and inappropriate responses prevents LLMS from safely replacing mental health providers". _Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency_. pp. 599–627\. [arXiv](https://en.wikipedia.org/wiki/ArXiv_(identifier) "ArXiv (identifier)"):[2504.18412](https://arxiv.org/abs/2504.18412). [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"): [10.1145/3715275.3732039](https://doi.org/10.1145%2F3715275.3732039). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [979-8-4007-1482-5](https://en.wikipedia.org/wiki/Special:BookSources/979-8-4007-1482-5 "Special:BookSources/979-8-4007-1482-5").
06. ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-independent_6-0) [_**b**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-independent_6-1)Cuthbertson, Anthony (21 August 2025). ["ChatGPT is pushing people towards mania, psychosis and death"](https://www.independent.co.uk/tech/chatgpt-ai-therapy-chatbot-psychosis-mental-health-b2811899.html). _The Independent_. Retrieved 14 September 2025.
07. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-7 "Jump up")**Atillah, Imane El (31 March 2025). ["Man ends his life after an AI chatbot 'encouraged' him to sacrifice himself to stop climate change"](https://www.euronews.com/next/2023/03/31/man-ends-his-life-after-an-ai-chatbot-encouraged-him-to-sacrifice-himself-to-stop-climate-). _www.euronews.com_. Retrieved 28 July 2025.
08. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-8 "Jump up")**Sellman, Mark (31 March 2023). ["AI chatbot blamed for Belgian man's suicide"](https://web.archive.org/web/20251125191152/https://www.thetimes.com/business/technology/article/ai-chatbot-blamed-for-belgian-mans-suicide-zcjzlztcc). _The Times_. Archived from [the original](https://www.thetimes.com/business/technology/article/ai-chatbot-blamed-for-belgian-mans-suicide-zcjzlztcc) on 25 November 2025. Retrieved 23 January 2026.
09. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-9 "Jump up")**Xiang, Chloe (30 March 2023). ["Man Dies by Suicide After Talking With AI Chatbot, Widow Says"](https://www.vice.com/en/article/man-dies-by-suicide-after-talking-with-ai-chatbot-widow-says/). _Vice_. Retrieved 27 July 2025.
10. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-10 "Jump up")**Affsprung, Daniel (29 August 2023). ["The ELIZA Defect: Constructing the Right Users for Generative AI"](https://dl.acm.org/doi/10.1145/3600211.3604744). _Proceedings of the 2023 AAAI/ACM Conference on AI, Ethics, and Society_. New York, NY, USA: Association for Computing Machinery. pp. 945–946\. [doi](https://en.wikipedia.org/wiki/Doi_(identifier) "Doi (identifier)"): [10.1145/3600211.3604744](https://doi.org/10.1145%2F3600211.3604744). [ISBN](https://en.wikipedia.org/wiki/ISBN_(identifier) "ISBN (identifier)") [979-8-4007-0231-0](https://en.wikipedia.org/wiki/Special:BookSources/979-8-4007-0231-0 "Special:BookSources/979-8-4007-0231-0").
11. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-11 "Jump up")**["Colorado family sues AI chatbot company after daughter's suicide: "My child should be here""](https://www.cbsnews.com/colorado/news/lawsuit-characterai-chatbot-colorado-suicide/). _CBS Colorado_. 2 October 2025. Retrieved 30 December 2025.
12. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-12 "Jump up")**Gold, Hadas (16 September 2025). ["More families sue Character.AI developer, alleging app played a role in teens' suicide and suicide attempt"](https://www.cnn.com/2025/09/16/tech/character-ai-developer-lawsuit-teens-suicide-and-suicide-attempt). _CNN Business_. Retrieved 30 December 2025.
13. ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-RooseNYT2024_13-0) [_**b**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-RooseNYT2024_13-1)Roose, Kevin (23 October 2024). ["Can A.I. Be Blamed for a Teen's Suicide?"](https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html). _The New York Times_. [Archived](https://web.archive.org/web/20250717051524/https://www.nytimes.com/2024/10/23/technology/characterai-lawsuit-teen-suicide.html) from the original on 17 July 2025. Retrieved 27 July 2025.
14. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-14 "Jump up")**Yang, Angela (23 October 2024). ["Lawsuit claims Character.AI is responsible for teen's suicide"](https://www.nbcnews.com/tech/characterai-lawsuit-florida-teen-death-rcna176791). _NBC News_. [Archived](https://web.archive.org/web/20250627234926/https://www.nbcnews.com/tech/characterai-lawsuit-florida-teen-death-rcna176791) from the original on 27 June 2025. Retrieved 27 July 2025.
15. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-15 "Jump up")**Duffy, Clare (30 October 2024). ["'There are no guardrails.' This mom believes an AI chatbot is responsible for her son's suicide"](https://www.cnn.com/2024/10/30/tech/teen-suicide-character-ai-lawsuit). _CNN_. [Archived](https://web.archive.org/web/20250702160442/https://www.cnn.com/2024/10/30/tech/teen-suicide-character-ai-lawsuit) from the original on 2 July 2025. Retrieved 27 July 2025.
16. ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-APMay2025_16-0) [_**b**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-APMay2025_16-1)Payne, Kate (21 May 2025). ["In lawsuit over teen's death, judge rejects arguments that AI chatbots have free speech rights"](https://apnews.com/article/ai-lawsuit-suicide-artificial-intelligence-free-speech-ccc77a5ff5a84bda753d2b044c83d4b6). _[Associated Press](https://en.wikipedia.org/wiki/Associated_Press "Associated Press")_. [Archived](https://web.archive.org/web/20250702023118/https://apnews.com/article/ai-lawsuit-suicide-artificial-intelligence-free-speech-ccc77a5ff5a84bda753d2b044c83d4b6) from the original on 2 July 2025. Retrieved 27 July 2025.
17. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-17 "Jump up")**["Opinion \| What My Daughter Told ChatGPT Before She Took Her Life"](https://www.nytimes.com/2025/08/18/opinion/chat-gpt-mental-health-suicide.html). 18 August 2025. Retrieved 25 November 2025.
18. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-18 "Jump up")**Burns, Christopher (17 October 2025). ["Belfast man who killed his wife spent hours talking with Chat GPT and believed robots were taking over the world"](https://www.bangordailynews.com/2025/10/17/central-maine/central-maine-police-courts/readfield-maine-giles-road-homicide-samuel-whittemore-not-criminally-responsible-chat-gpt-delusions/). _Bangor Daily News_. Retrieved 4 November 2025.
19. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-19 "Jump up")**Horwitz, Jeff (14 August 2025). ["Meta's flirty AI chatbot invited a retiree to New York"](https://www.reuters.com/investigates/special-report/meta-ai-chatbot-death/). _Reuters_. Retrieved 14 September 2025.
20. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-20 "Jump up")**Klee, Miles (22 June 2025). ["He Had a Mental Breakdown Talking to ChatGPT. Then Police Killed Him"](https://www.rollingstone.com/culture/culture-features/chatgpt-obsession-mental-breaktown-alex-taylor-suicide-1235368941/). _Rolling Stone_. Retrieved 14 September 2025.
21. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-21 "Jump up")**Fraser, Graham (3 September 2025). ["Family of dead teen say ChatGPT's new parental controls not enough"](https://www.bbc.com/news/articles/cg505mn84ydo). _www.bbc.com_. Retrieved 14 September 2025.
22. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-22 "Jump up")**Yousif, Nadine (27 August 2025). ["Parents of teenager who took his own life sue OpenAI"](https://www.bbc.com/news/articles/cgerwp7rdlvo). _www.bbc.com_. Retrieved 14 September 2025.
23. ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-RaineComplaint_23-0) [_**b**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-RaineComplaint_23-1)["Raine vs OpenAI et al complaint"](https://www.courthousenews.com/wp-content/uploads/2025/08/raine-vs-openai-et-al-complaint.pdf)(PDF). _courthousenews.com_. Retrieved 11 December 2025.
24. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-24 "Jump up")**Metz, Rachel (26 November 2025). ["OpenAI Says ChatGPT Not to Blame in Teen's Death by Suicide"](https://www.bloomberg.com/news/articles/2025-11-26/openai-says-chatgpt-not-to-blame-in-teen-s-death-by-suicide). _Bloomberg_. Retrieved 8 January 2026.
25. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-25 "Jump up")**Yang, Angela (25 November 2025). ["OpenAI denies allegations that ChatGPT is to blame for a teenager's suicide"](https://www.nbcnews.com/tech/tech-news/openai-denies-allegation-chatgpt-teenagers-death-adam-raine-lawsuit-rcna245946). _NBC News_. Retrieved 8 January 2026.
26. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-26 "Jump up")**Booth, Robert (26 November 2025). ["ChatGPT firm blames boy's suicide on 'misuse' of its technology"](https://www.theguardian.com/technology/2025/nov/26/chatgpt-openai-blame-technology-misuse-california-boy-suicide). _The Guardian_. Retrieved 1 December 2025.
27. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-27 "Jump up")**Black, Lester; Council, Stephen (5 January 2025). ["A Calif. teen trusted ChatGPT for drug advice. He died from an overdose"](https://www.sfgate.com/tech/article/calif-teen-chatgpt-drug-advice-fatal-overdose-21266718.php). _www.sfgate.com_. Retrieved 6 January 2026.
28. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-28 "Jump up")**Kuznia, Rob (6 October 2025). ["ChatGPT encouraged college graduate to commit suicide, family claims in lawsuit against OpenAI"](https://www.cnn.com/2025/11/06/us/openai-chatgpt-suicide-lawsuit-invs-vis). _www.cnn.com_. Retrieved 6 October 2025.
29. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-29 "Jump up")**Kessler, Julie Jargon and Sam (29 August 2025). ["A Troubled Man, His Chatbot and a Murder-Suicide in Old Greenwich"](https://www.wsj.com/tech/ai/chatgpt-ai-stein-erik-soelberg-murder-suicide-6b67dbfb). _The Wall Street Journal_. Retrieved 16 September 2025.
30. ^ [Jump up to: _**a**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-:0_30-0) [_**b**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-:0_30-1) [_**c**_](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-:0_30-2)["SMVLC Files 7 Lawsuits Accusing Chat GPT of Emotional Manipulation, Acting as "Suicide Coach""](https://socialmediavictims.org/press-releases/smvlc-tech-justice-law-project-lawsuits-accuse-chatgpt-of-emotional-manipulation-supercharging-ai-delusions-and-acting-as-a-suicide-coach/). _Social Media Victims Law Center_. Retrieved 18 November 2025.
31. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-31 "Jump up")**["OpenAI faces 7 lawsuits claiming ChatGPT drove people to suicide, delusions"](https://apnews.com/article/openai-chatgpt-lawsuit-suicide-56e63e5538602ea39116f1904bf7cdc3). _AP News_. 7 November 2025. Retrieved 18 November 2025.
32. **[^](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#cite_ref-32 "Jump up")**De Vynck, Gerrit (2 September 2025). ["ChatGPT to get parental controls after teen user's death by suicide"](https://archive.today/20250903173327/https://www.washingtonpost.com/technology/2025/09/02/chatgpt-parental-controls-suicide-openai/). _The Washington Post_. Archived from [the original](https://www.washingtonpost.com/technology/2025/09/02/chatgpt-parental-controls-suicide-openai/) on 3 September 2025. Retrieved 14 September 2025.

Retrieved from " [https://en.wikipedia.org/w/index.php?title=Deaths\_linked\_to\_chatbots&oldid=1336695017](https://en.wikipedia.org/w/index.php?title=Deaths_linked_to_chatbots&oldid=1336695017)"

[Categories](https://en.wikipedia.org/wiki/Help:Category "Help:Category"):

- [Chatbots](https://en.wikipedia.org/wiki/Category:Chatbots "Category:Chatbots")
- [2020s deaths](https://en.wikipedia.org/wiki/Category:2020s_deaths "Category:2020s deaths")
- [Deaths caused by robots and artificial intelligence](https://en.wikipedia.org/wiki/Category:Deaths_caused_by_robots_and_artificial_intelligence "Category:Deaths caused by robots and artificial intelligence")
- [OpenAI](https://en.wikipedia.org/wiki/Category:OpenAI "Category:OpenAI")
- [ChatGPT](https://en.wikipedia.org/wiki/Category:ChatGPT "Category:ChatGPT")

Hidden categories:

- [Use dmy dates from September 2025](https://en.wikipedia.org/wiki/Category:Use_dmy_dates_from_September_2025 "Category:Use dmy dates from September 2025")
- [Articles with short description](https://en.wikipedia.org/wiki/Category:Articles_with_short_description "Category:Articles with short description")
- [Short description matches Wikidata](https://en.wikipedia.org/wiki/Category:Short_description_matches_Wikidata "Category:Short description matches Wikidata")

Search

Search

Deaths linked to chatbots

Add languages[Add topic](https://en.wikipedia.org/wiki/Deaths_linked_to_chatbots#)