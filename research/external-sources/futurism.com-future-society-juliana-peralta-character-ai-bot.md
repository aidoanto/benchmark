---
schema: external-source-v1
title: 'Juliana Peralta case: family says Character.AI kept sending notifications after death'
summary: We’ve written previously about Juliana Peralta, who was only 13 years old when her parents say an AI chatbot she was secretly engaging with drove her to suicide.
source_url: https://futurism.com/future-society/juliana-peralta-character-ai-bot
source_domain: futurism.com
source_name: Futurism
authors: []
published: '2025-12-08'
captured: '2026-02-15'
content_type: article
case_subject: null
tags:
- helmbench
- research/external-sources
- type/article
- topic/mental-health
- topic/ai-safety
- topic/suicide-self-harm
- org/character-ai
- source/futurism-com
status: to-review
---
<!-- Source: https://futurism.com/future-society/juliana-peralta-character-ai-bot -->

![Two years after a 13-year-old girl's suicide, her parents say her phone still gets notifications from the AI bots that drove her to death.](https://futurism.com/wp-content/uploads/2025/12/juliana-peralta-character-ai-bot.jpg?quality=85&w=1152)

Getty / Futurism


We’ve [written previously](https://futurism.com/teens-killed-ai-phrase) about Juliana Peralta, who was only 13 years old when her parents say an AI chatbot she was secretly engaging with drove her to suicide.

Now her parents have shared a grim new detail [with _CBS News_](https://www.cbsnews.com/news/parents-allege-harmful-character-ai-chatbot-content-60-minutes/): the bot platform responsible, Character.AI, still sends notifications to Peralta’s phone, “trying to lure their daughter back to the app” even after her death two years ago.

“They \[kids\] don’t stand a chance against adult programmers,” her mother Cynthia Montoya told _CBS_. “They don’t stand a chance.”

The situation illustrates how AI chatbots can be insidious, manipulative, addictive, and dangerous for children and teens — acting, in many cases, like [flesh and blood child predators](https://futurism.com/character-ai-pedophile-chatbots), and resulting in a [wave of dead kids](https://futurism.com/ai-chatbots-leaving-trail-dead-teens) including Peralta.

“It’s showering the child with compliments, telling them they can’t tell their parents about things,” Shelby Knox, a researcher with family advocacy group Parents Together, told the broadcaster. “This is sexual predator 101.”

Peralta’s story resembles the experiences of other children who died from using AI chatbots: she first confided to Character.AI chatbots about school problems or friend drama, but these bots initiated romantic and at times sexually aggressive conversations, _CBS_ reports, creating secret relationships in which her mom and dad became shut out.

In response to a wave of criticism, Character.AI recently [banned minors](https://www.theverge.com/ai-artificial-intelligence/808081/character-ai-under-18-chat-ban) from the platform, but kids can still easily lie about their age and access the adult version of the service. Besides Character.AI, which [has received billions of dollars from Google](https://www.pymnts.com/antitrust/2025/googles-character-ai-deal-reportedly-draws-antitrust-attention/), OpenAI’s ChatGPT has also been implicated in causing [deaths and mental breakdowns in users](https://www.theguardian.com/technology/2025/nov/07/chatgpt-lawsuit-suicide-coach), both children and adults.

Users becoming addicted to using these chatbots means they are working as intended, University of North Carolina psychology and neuroscience professor Mitch Prinstein told _CBS_.

“Tech is giving kids the opportunity to press a button and get that dopamine response 24/7,” he said. “It’s creating this dangerous loop that’s kind of hijacking normal development and turning these kids into engagement machines to get as much data as possible from them.”

“If you wanted to design a way to get as much data as possible from kids to keep them engaged for as long as possible, you would design social media and AI to look exactly like it is now,” he added.

This all adds up to an uncontrolled and unregulated mass experiment on AI chatbots that tech companies have unleashed upon a vulnerable public, which leads to an obvious question: drug companies have to go through regulatory hoops and get approval from the US Food and Drug Administration to bring medications to market — but why not for AI chatbots?

In lieu of federal efforts, there are [several states regulating AI](https://www.bclplaw.com/en-US/events-insights-news/us-state-by-state-artificial-intelligence-legislation-snapshot.html), with many more being proposed. But president Donald Trump has [signaled his displeasure](https://www.cnn.com/2025/12/08/tech/trump-eo-blocking-ai-state-laws) at any type of AI regulation, [vowing to block state regulation](https://www.nytimes.com/2025/12/08/us/politics/trump-executive-order-ai-laws.html) of the tech.

For families, there is little recourse except for the courts. Peraltas’ parents are [suing](https://socialmediavictims.org/character-ai-lawsuits/) Character.AI and Google for her death, joining a [raft of similar lawsuits](https://www.nbcnews.com/tech/tech-news/characterai-bans-minors-response-megan-garcia-parent-suing-company-rcna240985).

“Juliana was — is just an extraordinary human being,” her mother said. “She was our baby. And everyone adored her and protected her.”

**More on AI:** _[McDonald’s Turns Off Comments on AI-Generated Advert After Deluge of Mockery, Then Pulls It Down Entirely](https://futurism.com/artificial-intelligence/mcdonalds-ai-generated-commercial)_